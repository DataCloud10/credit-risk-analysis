{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e9f5f8 ; padding: 40px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 48px; font-weight: bold;\">IL RISCHIO DI CREDITO:UN'ANALISI PREDITTIVA </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset di origine simlulativa che andrò ad analizzare riguarda una lista di prestiti richiesti ad istituti di credito. Lo  scopo dell'analisi è cercare di ricondurre il range di caratteristiche di chi accede al ramo creditizio all'esito della procedura di rimborso: capire quindi se dalle caratteristiche del debitore sia possibile dedurre se il prestito erogato sarà rimborsato o meno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installazione librerie necessarie\n",
    "!pip install pandas==latest_version\n",
    "!pip install numpy==latest_version\n",
    "!pip install matplotlib==latest_version\n",
    "!pip install seaborn==latest_version\n",
    "!pip install scikit-learn==latest_version\n",
    "!pip install imbalanced-learn==latest_version\n",
    "!pip install xgboost==latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librerie e pacchetti necessari\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import del dataset\n",
    "df=pd.read_csv('credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample del dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e9f5f8 ; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">Descrizione delle variabili</h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: \t#F0F8FF ; padding: 15px; border-radius: 10px; color: #191970; margin-top: 20px; text-align: left;\">\n",
    "    <ul>\n",
    "        <li><b>person_age:</b> Età dell’individuo che richiede il prestito.</li>\n",
    "        <li><b>person_income:</b> Reddito annuale dell’individuo.</li>\n",
    "        <li><b>person_home_ownership:</b> Tipo di proprietà di casa dell’individuo.\n",
    "            <ul>\n",
    "                <li>rent: L'individuo è in affitto.</li>\n",
    "                <li>mortgage: L’individuo ha un mutuo sulla proprietà che possiede.</li>\n",
    "                <li>own:  L'individuo detiene la proprietà di casa.</li>\n",
    "                <li>other: Altre categorie di proprietà di casa che possono essere specifiche per il dataset.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>person_emp_length:</b> Durata dell’impiego dell’individuo  (in anni).</li>\n",
    "        <li><b>loan_intent:</b> La motivazione per la richiesta di prestito.</li>\n",
    "        <li><b>loan_grade:</b> La valutazione assegnata al prestito in base alla solvibilità del mutuatario.\n",
    "            <ul>\n",
    "                <li>A: Il mutuatario ha un’elevata solvibilità, che si traduce in un basso rischio.</li>\n",
    "                <li>B: Il mutuatario è relativamente a basso rischio, ma non così solvibile come nel caso A.</li>\n",
    "                <li>C: La solvibilità del mutuatario è moderata.</li>\n",
    "                <li>D: Si considera che il mutuatario abbia un rischio maggiore rispetto ai casi precedenti.</li>\n",
    "                <li>E: La solvibilità del mutuatario è inferiore, che si traduce in un rischio maggiore.</li>\n",
    "                <li>F: Il mutuatario rappresenta un notevole rischio di credito.</li>\n",
    "                <li>G: La solvibilità del mutuatario è la più bassa, portando al rischio più alto.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>loan_amnt:</b>  L’importo del prestito richiesto dall’individuo.</li>\n",
    "        <li><b>loan_int_rate:</b> Il tasso di interesse legato al prestito.</li>\n",
    "        <li><b>loan_status:</b> Stato del prestito, dove 0 indica non inadempimento e 1 indica inadempimento.\n",
    "            <ul>\n",
    "                <li>0: Non inadempimento - Il mutuatario ha rimborsato con successo il prestito come concordato, e non c’è stato inadempimento.</li>\n",
    "                <li>1: Inadempimento - Il mutuatario non è riuscito a rimborsare il prestito secondo i termini concordati e ha inadempiuto al prestito.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>loan_percent_income:</b> Il rapporto in percentuale tra importo del prestito e il reddito annuale dell'individuo.</li>\n",
    "        <li><b>cb_person_default_on_file:</b> Storico delle inandempienze dell'individuo secondo le agenzie di credito.\n",
    "            <ul>\n",
    "                <li>Y:  L’individuo ha inandempienze nello storico di credito.</li>\n",
    "                <li>N: L'individuo non ha inandempienze nello storico di credito.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>cb_preson_cred_hist_length:</b>  La lunghezza dello storico di credito dell’individuo.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e9f5f8 ; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">EXPLORATORY DATA ANALYSIS</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensioni del dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colonne del dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caratteri statistici delle variabili numeriche del dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalla funzione *describe* già è possibile scorgere alcune informazioni del dataset in questione: escludendo la variabile *loan status* che consideriamo target della nostra analisi, in tutte le features il valore \"max\" dista più di due scarti quadratici \"std\" dal 75° percentile, il che denota la presenza di outliers. Le distribuzioni invece verso il basso appaiono più appiattite vista la vicinanza dei valori \"min\" al 25° percentile (praticamente tutti entro lo scarto quadratico).\n",
    "\n",
    "Da notare che per le variabili *person_age* e *person_emp_length* i valori \"max\" rappresentino dei veri e propri refusi vista una presunta età di 144 anni e una carriera lavorativa di 123 anni.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tipi delle variabili del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#presenza di elementi nulli\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due features presentano parecchi valori nulli, toccherà valutare in un secondo momento come trattarli in base alla porzione di dataset che ricoprono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero di valori assunti da ogni variabile del dataset\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione *nunique* ci mostra il numero di valori assunti da ogni variabile del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampo per ogni feature il rispettivo value_counts per vedere come si distribuiscono le variabili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabelle di frequenza assoluta delle variabili del dataset\n",
    "value_counts = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    value_counts[column] = df[column].value_counts()\n",
    "\n",
    "for column, counts in value_counts.items():\n",
    "    print(f\"Feature {column}:\")\n",
    "    print(counts)\n",
    "    print(\"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il conteggio dei valori assunti dalle modalità delle features conferma che alcune di esse vadano raggruppate in intervalli per una visualizzazione più compatta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# riprendo valori minimi, massimi e numero di valori assunti delle variabili in un dataframe\n",
    "minimi = df.min(numeric_only=True)\n",
    "massimi = df.max(numeric_only=True)\n",
    "counts=df.nunique()\n",
    "\n",
    "df_min_max = pd.DataFrame({'Min': minimi, 'Max': massimi, 'Counts':counts})\n",
    "\n",
    "df_min_max.sort_values(by='Counts',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto che il dataset contiene sia variabili continue che discrete vado a rappresentarle usando diversi grafici.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n",
    "\n",
    "# Variabili discrete\n",
    "categorical_features = ['person_home_ownership', 'loan_intent', 'loan_grade', 'loan_status', 'cb_person_default_on_file']\n",
    "\n",
    "# Creazione di grafici per le variabili continue\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Istogramma\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data=df, x=feature, kde=True)\n",
    "    plt.title(f'{feature} histogram')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=df, x=feature)\n",
    "    plt.title(f'{feature} boxplot')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalle distribuzioni delle variabili numeriche diventa facile più facile estrarre qualche informazione sul dataset:\n",
    "\n",
    "- 'person_age': La maggior parte delle persone nel dataset sembra avere tra i 20 ai 30 anni.\n",
    "- 'person_income': la maggior parte dei redditi si concentra entro i 25000 dollari(?)\n",
    "- 'person_emp_length': La maggior parte delle persone nel dataset ha una ha una carriera lavorativa compresa tra gli 0 e 20 anni.\n",
    "- 'loan_amnt': La maggior parte delle persone nel dataset ha preso in prestito un importo inferiore a 10000 dollari.\n",
    "- 'loan_int_rate': La maggior parte delle persone nel dataset ha un tasso di interesse sui prestiti intorno al 10%.\n",
    "- 'loan_percent_income': La maggior parte delle persone nel dataset non si espone paricolarmente prendendo prestiti di importo relativamente basso rispetto al proprio reddito.\n",
    "- 'cb_person_cred_hist_length': La maggior parte delle persone nel dataset ha uno storico di credito che non supera i dieci anni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I boxplot aiutano a capire se il range dei valori assunti dalle variabili sia dovuto a un effettiva distribuzione uniforme o ad outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con dei grafici a torta vado a vedere in maniera più precisa come si distribuiscono le modalità delle features categoriche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creazione dizionario con commenti per ogni grafico\n",
    "commenti = [\n",
    "     'Dal grafico è facile notare come praticamente 9 persone su 10 che richiedono il prestito sono in affitto o con mutuo pendente sulla propria casa. ',\n",
    "     'Lo scopo del prestito invece vede un sostanziale equilibrio a leggero discapito di chi lo chiede per apportare migliorie alla casa.',\n",
    "     '8 prestiti su 10 sono concessi a clienti con solvibilità medio-alta.',\n",
    "    'Sul totale dei prestiti concessi 8 su 10 sono stati correttamente rimborsati alla banca',\n",
    "    'Solo una persona richiedente il prestito su 6 ha nel proprio storico insolvenze.']\n",
    "\n",
    "for feature, commento in zip(categorical_features, commenti):\n",
    "    \n",
    "    serie = df[feature].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # grafico a torta\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.patch.set_facecolor('#FFFFFF')  \n",
    "    wedges, texts, autotexts = ax.pie(serie, labels = serie.index, autopct='%1.1f%%', pctdistance=0.85, wedgeprops=dict(width=0.3),textprops={'color':'#191970'})\n",
    "    \n",
    "    # setto il titolo e la dimensione\n",
    "    ax.set_title(f'{feature} piechart'.upper(), fontsize=20,color='#191970')\n",
    "    \n",
    "    # commento e suo posizionamento\n",
    "    ax.text(0.5, -0.1, commento, transform=ax.transAxes, fontsize=18, verticalalignment='center', family='serif', ha='center',color='#191970')\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dato importante di cui tenere conto nelle fasi di preprocessing è lo sbilanciamento della classe target 'loan_status'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi multivariata ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il primo step dell'analisi a più variabili è la rappresentazione degli scatterplot a coppie di variabili. In questo caso aggiungo come variabile distintiva dei punti la feature *loan status* che viene considerata la variabile target del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='loan_status')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa prima rappresentazione ci permette di vedere in quali grafici i punti di diverso colore si collocano in parti idealmente separabili, ciò implica in tali casi che le variabili coinvolte hanno una maggior influenza sull'esito della nostra variabile target.\n",
    "\n",
    "# <p align=center>![Loan Percent Income](images/loanpercentincome.png)</p>\n",
    "Per esempio nella riga relativa alla variabile *loan_percent_income* è facile notare in ognuna delle colonne che i punti arancioni - indicanti i prestiti non rimborsati - si collochino nella parte alta del grafico. Questo denota che all'aumentare del rapporto tra l'importo del prestito e il reddito annuo dell'individuo aumenti la possibilità che questo non riesca a saldare il prestito ottenuto. \n",
    "Questo trend trova conferma nel grafico sulla diagonale( penultimo riquadro) dove è visibile che oltre un certo 'rapporto' i prestiti insoluti superino quelli rimborsati.\n",
    "\n",
    "Qualcosa di simile anche se in maniera meno netta si osserva relativamente alla feature *loan_int_rate*, quindi il tasso di interesse è un'altra componente del prestito che all'aumentare riduce le possibilità che esso sia ripagato dal debitore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poi vado a rappresentare la matrice di correlazione tra le variabili numeriche per evidenziare eventuali legami tra di esse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "corr =numerical_df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True,\n",
    "    annot=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "plt.title('Correlation Heatmap of the Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le uniche coppie che presentano valori di correlazioni significativi sono quelle che legano l'età del richiedente alla lunghezza del suo storico di credito( il che è abbastanza logico ) e quella composta da importo del prestito e la percentuale del reddito dell'individuo che ricopre( anche qui la cosa è ovvia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Esiste quindi un rapporto tra il reddito dell'individuo e l'importo del prestito richiesto?** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot tra le due variabili con linea di regressione \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='person_income', y='loan_amnt', data=df, scatter_kws={'alpha':0.5})\n",
    "plt.title('Rapporto tra Reddito e Importo del Prestito')\n",
    "plt.xlabel('Reddito')\n",
    "plt.ylabel('Importo del Prestito')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche se i punti sono molto concentrati la linea di regressione conferma la correlazione positiva tra il reddito e l'importo del prestito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esiste un legame tra la motivazione del prestito e la possibilità che venga rimborsato? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='loan_intent', hue='loan_status', data=df)\n",
    "plt.title(\"Loan Status based on Loan Intent\")\n",
    "plt.xlabel('Loan Intent')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il grafico a barre dà un'indicazione ma per maggiore precisione calcolo il rapporto tra prestiti in default e non per ogni motivo della richiesta:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['loan_intent', 'loan_status']).size().unstack()\n",
    "\n",
    "#creazione valore di rapporto tra loan 1 e loan 0\n",
    "grouped['ratio'] = (grouped[1] / grouped[0])\n",
    "#ordinamento decrescente\n",
    "sorted_ratio = grouped['ratio'].sort_values(ascending=False)\n",
    "\n",
    "sorted_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classifica indica che dalla motivazione del prestito si può iniziare a comprendere la possibilità di rimborso. i prestiti richiesti per saldare vecchi debiti sono la categoria più incline al possibile default (4 su 10 prestiti non rimborsati), seguono i prestiti per spese mediche, altra incombenza a volte non prevedibile pertanto non programmabile. Menzione anche per i prestiti per i miglioramenti della casa , che seppur rappresentino la motivazione di gran lunga meno frequente hanno un alto tasso di default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il tasso di interesse concesso determina il rimborso del prestito? ###\n",
    "\n",
    "Un'altra variabile che l'istituto può controllare in sede di stipula del prestito è il tasso di interesse concesso al richiedente. Può questo influire sulle possibilità del debitore di rimborsare correttamente l'importo erogato?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='loan_status', y='loan_int_rate', data=df)\n",
    "plt.title(\"Loan Status vs Loan Interest Rate\")\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Loan Interest Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasso di interesse medio per stato del prestito\n",
    "df.groupby('loan_status')['loan_int_rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il box-plot è abbastanza chiaro nel \"raccontare\" che i prestiti non rimborsati abbiano un range di tassi di interesse significativamente diverso da quelli correttamente pagati. Valore confermato con una media di quasi 3 punti percentuali in più per i prestiti in default. Questo conferma che tassi di interesse più alti si leghino a un tasso di inadempimento maggiore.\n",
    "Bisogna quindi capire a chi vengono concessi tassi di interesse più alti.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esiste un rapporto tra tasso di interesse concesso e la porzione del reddito rappresentata dal prestito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='loan_percent_income', y='loan_int_rate', hue='loan_status', data=df, alpha=0.7)\n",
    "plt.title('Loan Percent of Income vs Loan Interest Rate')\n",
    "plt.xlabel('Loan Percent of Income')\n",
    "plt.ylabel('Loan Interest Rate (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo scatter-plot mette in relazione il tasso di interesse del prestito e che porzione del reddito del richiedente va a coprire. Il grafico mostra chiaramente che oltre un certo rapporto prestito-reddito(circa 0,3) le insolvenze comincino a distribuirsi a prescindere dal tasso di interesse, mentre prima si nota una sorta di \"comfort-zone quadrata\": con tassi di interesse inferiori al 14% e un rapporto prestito-reddito inferiore al 30% si ha una quasi certezza della restituzione del prestito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3faf3; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">FEATURE ENGINEERING</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il primo passaggio fondamentale consiste nel trattamento dei valori nulli all'interno del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentuale_nulli = df.isnull().sum() / len(df) * 100\n",
    "df_nulli = pd.DataFrame({'Feature': df.columns,\n",
    "                         'percentuale_nulli':  percentuale_nulli.values})\n",
    "df_nulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essi rappresentano percentuali basse delle uniche due variabili dove sono presenti pertanto possono essere rimossi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['person_emp_length', 'loan_int_rate'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente vado a riprendere la distribuzione dell'età dei richiedenti il prestito:\n",
    "\n",
    "# <p align=left>![age.png](images/age.png)</p>\n",
    "\n",
    "Visto che di fatto oltre gli 80 anni ci sono solo outliers ed errori di compilazione posso rimuovere quegli elementi dal dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.person_age <=80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Altra variabile sulla quale servono correzioni è la *person_emp_length* che riporta un valore di 123 decisamente errato:\n",
    "\n",
    "# <p align=left>![personemlength.png](images/personemlength.png)</p>\n",
    "\n",
    "valore che andrò a rimuovere:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.person_emp_length <=60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo il nuovo valore massimo\n",
    "df.person_emp_length.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche la variabile relativa al reddito presenta un valore che seppur plausibile si discosta fortemente dalla distribuzione dei restanti valori:\n",
    "\n",
    "# <p align=left>![personemlength.png](images/personincome.png)</p>\n",
    "\n",
    "pertanto rimuovo anche questo valore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.person_income<3000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo il nuovo valore massimo\n",
    "df.person_income.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le restanti variabili numeriche non presentano anomalie pertanto le conservo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una copia del dataset prima di passare alla fase di preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df=df.copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3faf3; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">DATA PREPROCESSING</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset contiene sia features numeriche che categoriche. In preprocessing applico la standardizzazione alle prime per averle tutte nella stessa 'scala' di valori. Per le categoriche applico la funzione One-Hot-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione colonne in due liste\n",
    "num_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n",
    "cat_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "\n",
    "# creazione trasformatori\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# combinazione dei trasformatori\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso ora dividere il dataset in variabili dipendenti e variabile target e applicare la combinazione dei trasformatori per i due tipi di variabile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('loan_status', axis=1)\n",
    "y = df['loan_status']\n",
    "\n",
    "X= preprocessor.fit_transform(X)\n",
    "\n",
    "df.columns = df.columns.to_series().apply(lambda x: x.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensioni delle due variabili\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divido il dataset in parte per l'addestramento e parte di test con stratify visto lo sbilanciamento delle classi\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3faf3; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">VALUTAZIONE MODELLI</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prime prove sul dataset le faccio testando vari algoritmi adatti alla classificazione binaria e registrando i risultati in un dataframe per un confronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo dizionario con algoritmi da testare\n",
    "algoritmi = {\n",
    "    'Regressione logistica': LogisticRegression(),\n",
    "    'Albero di decisione': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_algorithms(algoritmi, X, y, cv=5):    #funzione che scorre i vari algoritmi con cross validation a 5 fold di default e li testa sui set di dati inseriti\n",
    "    # Definisco le metriche\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "\n",
    "    # Risultati da memorizzare\n",
    "    risultati = {}\n",
    "\n",
    "    # Testo ogni algoritmo\n",
    "    for nome, algoritmo in algoritmi.items():\n",
    "        print(f\"Testing {nome}...\")\n",
    "        scores = cross_validate(algoritmo, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        # Memorizzo i risultati \n",
    "        risultati[nome] = {\n",
    "            'accuracy': scores['test_accuracy'].mean(),\n",
    "            'precision': scores['test_precision_weighted'].mean(),\n",
    "            'recall': scores['test_recall_weighted'].mean(),\n",
    "            'f1_score': scores['test_f1_weighted'].mean(),\n",
    "            'roc_auc': scores['test_roc_auc'].mean()\n",
    "        }\n",
    "\n",
    "    # inserisco in un Dataframe i risultati\n",
    "    df_risultati = pd.DataFrame(risultati).transpose()\n",
    "\n",
    "    return df_risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso la funzione sul set di addestramento\n",
    "report=test_algorithms(algoritmi,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutando l'accuracy l'algoritmo migliore sembra essere il Random Forest. Ma bisogna tenere conto,vista la natura del problema, di qualche considerazione:\n",
    "* sarà fortemente importante ridurre i cosiddetti **falsi positivi(FP)**, quei soggetti che vengono classificati come solventi, quindi meritevoli della concessione del credito quando in realtà non ne possiedono i requisiti.Una loro errata classificazione rappresenta un danno finanziario per la banca.\n",
    "\n",
    "* meno dannoso ma comunque meritevole di attenzione è il corretto riconoscimento dei **falsi negativi(FN)**, coloro che avrebbero i requisiti per poter ottenere il credito ma classificati come inadempienti. Il danno qui è legato al mancato guadagno per la concessione di un credito che sarebbe sicuro e solvibile.\n",
    "\n",
    "Quando i costi dei falsi positivi sono alti come nel caso in esame la metrica più importante è la **precision** che rileva la percentuale di veri positivi sul totale dei positivi predetti dal modello(veri positivi+ falsi positivi).\n",
    "La metrica **recall** invece serve per controllare i falsi negativi e si calcola rapportando i TP alla totalità dei casi positivi reali (TP + FN).\n",
    "\n",
    "​Le due metriche però portano a un trade-off poichè se una aumenta l'altra diminuisce e viceversa.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_results(df_risultati):\n",
    "    metrics = ['accuracy', 'precision', 'f1_score']\n",
    "    palettes = ['Blues_r', 'Greens_r', 'Reds_r']  # Scegli le palette che preferisci\n",
    "\n",
    "    for metric, palette in zip(metrics, palettes):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df_sorted = df_risultati.sort_values(by=metric, ascending=False)\n",
    "        \n",
    "        plt.barh(df_sorted.index, df_sorted[metric], color=sns.color_palette(palette, len(df_sorted)))\n",
    "        plt.title(f'Modelli ordinati per {metric}')\n",
    "        plt.xlabel(metric)\n",
    "\n",
    "        # Aggiungi l'etichetta del modello e il punteggio per ogni barra\n",
    "        for i, (model, score) in enumerate(df_sorted[metric].items()):\n",
    "            plt.text(score, i, f'{score:.2f}', va='center')\n",
    "\n",
    "        plt.gca().invert_yaxis()  # Inverte l'ordine delle barre\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Utilizza la funzione\n",
    "\n",
    "plot_results(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tre algoritmi che ottengono i risultati migliori sono XGBoost,Random Forest e Gradient Boosting . Ho plottato anche la chart secondo la Precision  perchè vista la natura del problema reputo preminente che siano pochi i falsi positivi ed è la metrica che può garantirlo. Per sicurezza anche f1 score(media armonica tra precisione recall) conferma la graduatoria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3faf3; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">TUNING DEGLI IPERPARAMETRI</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prima di combinare l'azione dei modelli con un metodo ensemble procedo a fare il tuning dei parametri di ognuno di essi, per non appesantire troppo i calcoli uso RandomizeSearchCV e non il più esaustivo ma \"pesante\" GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#creo i dizionari con i parametri di ogni algoritmo scelto\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8, None],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "\n",
    "gb_param_grid = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params_grid = {\n",
    "    \"n_estimators\": np.arange(50, 200, 10),\n",
    "    \"max_depth\": np.arange(2, 10, 2),\n",
    "    \"learning_rate\": np.linspace(0.01, 0.1, 10),\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, n_iter=50, cv=5, n_jobs=-1,verbose=3)\n",
    "\n",
    "# fit del modello\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# trovo i parametri ottimali\n",
    "rf_best_params = rf_random.best_params_\n",
    "\n",
    "# faccio lo stesso  per Gb e Svc\n",
    "gb_random = RandomizedSearchCV(GradientBoostingClassifier(random_state=42), gb_param_grid, n_iter=50, cv=5, n_jobs=-1,verbose=3)\n",
    "gb_random.fit(X_train, y_train)\n",
    "gb_best_params = gb_random.best_params_\n",
    "\n",
    "xgb_random = RandomizedSearchCV(XGBClassifier(random_state=42), xgb_params_grid, n_iter=50, cv=5, n_jobs=-1,verbose=3)\n",
    "xgb_random.fit(X_train, y_train)\n",
    "xgb_best_params = xgb_random.best_params_\n",
    "\n",
    "# estraggo i parametri ottimali per ciascun modello\n",
    "print(\"Random Forest best parameters: \", rf_best_params)\n",
    "print(\"Gradient Boosting best parameters: \", gb_best_params)\n",
    "print(\"XGB best parameters: \", xgb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta ottenuti i **best_params** di ognuno dei tre algoritmi vado creare il mio Voting Classifier settando ognuno dei tre modelli con le impostazioni migliori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf1 = RandomForestClassifier(**rf_best_params)\n",
    "clf2 = GradientBoostingClassifier(**gb_best_params)\n",
    "clf3 = XGBClassifier(**xgb_best_params)\n",
    "\n",
    "# creo oggetto ensemble\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('rf', clf1), ('gb', clf2), ('xgb', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "eclf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta fittato il metodo ensemble vado a riapplicare la funzione **test_algorithms** passando stavolta il solo ensemble anzichè la lista di algoritmi. Questo per metterlo nelle stesse condizioni nelle quali ho testato gli altri algoritmi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm(nome, modello, X, y, cv=5):\n",
    "    # Definizione metriche\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "\n",
    "    risultati = {}\n",
    "\n",
    "    # Test del modello\n",
    "    print(f\"Testing {nome}...\")\n",
    "    scores = cross_validate(modello, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    # registrazione risultati\n",
    "    risultati[nome] = {\n",
    "        'accuracy': scores['test_accuracy'].mean(),\n",
    "        'precision': scores['test_precision_weighted'].mean(),\n",
    "        'recall': scores['test_recall_weighted'].mean(),\n",
    "        'f1_score': scores['test_f1_weighted'].mean(),\n",
    "        'roc_auc': scores['test_roc_auc'].mean()\n",
    "    }\n",
    "\n",
    "    # trasformazione dei risultati in un dataframe\n",
    "    df_risultato = pd.DataFrame(risultati[nome], index=[nome])\n",
    "    return df_risultato\n",
    "\n",
    "    \n",
    "\n",
    "# Applicazione al modello Ensemble\n",
    "df_ensemble = test_algorithm('Voting Ensemble', eclf, X_train,y_train,cv=10) \n",
    "\n",
    "# Aggiunta dei risultati al dataframe esistente report\n",
    "df_risultati = pd.concat([report, df_ensemble])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risultati.style.highlight_max(color = 'blue', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo Ensemble migliora praticamente tutte le metriche dei modelli precedenti eccetto un trascurabile abbassamento della roc_auc.\n",
    "Visti i risultati già ottimali non sembra necessario calibrare i parametri in maniera diversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f3faf3; padding: 10px; border-radius: 10px; color: #191970; text-align: center; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"font-size: 24px;\">VALUTAZIONE FINALE DEL MODELLO e CONCLUSIONI</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo ensemble si è mostrato ottimo alle prese col set di addestramento. Ora è il momento di valorizzarlo alle prese con la porzione di dataset pulita, quella ancora non utilizzata in nessuna delle fasi precedenti.A tal fine creo una funzione che prenda come parametri il modello, le features di test e il target di test e i risultati del modello sull'addestramento.\n",
    "\n",
    "La funzione costruirà la matrice di confusione, il classification report, stamperà su un dataframe le metriche calcolate e le confronterà con quelle trovate in fase di addestramento per valutare eventuale overfitting del modello ai dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, df_ensemble, model_name):\n",
    "    # Previsioni\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Calcolo matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Generazione heatmap matrice di confusione\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # Stampa report di classificazione\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calcol di  ROC Curve e AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Visualizzazione ROC Curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # metriche\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Dataframe dei risultati\n",
    "    df_results = pd.DataFrame({\n",
    "        'accuracy': [accuracy],\n",
    "        'precision': [precision],\n",
    "        'recall': [recall],\n",
    "        'f1_score': [f1],\n",
    "        'roc_auc': [roc_auc]\n",
    "    }, index=[model_name])\n",
    "\n",
    "    # Unione col vecchio dataset\n",
    "    df_ensemble_updated = pd.concat([df_ensemble, df_results])\n",
    "    \n",
    "    # Grafico a barre \n",
    "    df_ensemble_updated.T.plot(kind='bar', figsize=(10,7), color=['skyblue', 'darkblue'])\n",
    "    plt.title('Confronto tra metriche di train e test')\n",
    "    plt.ylabel('Valore')\n",
    "    plt.xlabel('Metriche')\n",
    "    plt.show()\n",
    "    \n",
    "    return df_ensemble_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(eclf,X_test,y_test,df_ensemble,'Voting Ensemble Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello mantiene metriche molto buone anche sulla fase di test, migliorando lievemente persino i punteggi ottenuti in addestramento pertanto può essere ritenuto valido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parte finale del modello che può dare qualche informazione in più riguarda la cosiddetta **feature importance** , cioè quanto ogni singola variabile pesi sui risultati del nostro modello.\n",
    "\n",
    "Solitamente il procedimento viene svolto sul singolo algoritmo, quando usiamo metodi ensemble è necessario calcolare la feature importance su ogni singolo modello utilizzato e calcolare una sorta di media dei valori trovati.\n",
    "\n",
    "Inoltre avendo applicato dei metodi di preprocessing sulle variabili categoriche sarà necessario recuperare queste variabili altrimenti il numero di features non corrisponderebbe col numero di colonne del dataset originario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = preprocessor.named_transformers_\n",
    "\n",
    "# Start with the numeric features\n",
    "features = list(num_cols)\n",
    "\n",
    "# Then add the one-hot encoded categorical features\n",
    "cat_encoder = transformers['cat']['onehot']\n",
    "cat_one_hot_features = list(cat_encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "# Combine\n",
    "features += cat_one_hot_features\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "\n",
    "for name, estimator in eclf.named_estimators_.items():\n",
    "    if hasattr(estimator, 'feature_importances_'):\n",
    "        fi = pd.DataFrame({\n",
    "            'Feature': features,\n",
    "            'Importance': estimator.feature_importances_,\n",
    "        })\n",
    "        fi['Model'] = name\n",
    "        feature_importances = feature_importances.append(fi)\n",
    "\n",
    "# Average feature importances across models\n",
    "average_feature_importances = feature_importances.groupby('Feature')['Importance'].mean().reset_index()\n",
    "\n",
    "average_feature_importances.sort_values(by='Importance',ascending=False,inplace=True)\n",
    "average_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_feature_importances.sort_values(by='Importance', ascending=True, inplace=True)\n",
    "\n",
    "# setto le dimensioni del grafico\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# barplot orizzontale con palette di colori arcobaleno\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(average_feature_importances)))\n",
    "plt.barh(average_feature_importances['Feature'], average_feature_importances['Importance'], align='center', color=colors)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico mostra che le prime variabili in ordine di importanza nella predizione del rischio di inadempienza sono:\n",
    "\n",
    "* **loan_percent_income** : come avevamo già visto in fase di EDA la percentuale del prestito sul reddito individuale è una variabile fortemente significativa per il buon esito del rimborso\n",
    "\n",
    "* **person_home_ownership_RENT**:la seconda variabile per importanza è una di quelle create col one-hot-encoder,il fatto che chi richiede il prestito sia in affitto chiaramente denota una meno ampia possibilità finanziaria pertanto un maggior rischio di inadempienza\n",
    "\n",
    "* **loan_int_rate**: anche il tasso di interesse sul prestito già in fase di analisi esplorativa aveva mostrato un buon potere predittivo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queste variabili sono monitorabili in fase di richiesta del prestito pertanto l'istituto può sicuramente porre attenzione su queste caratteristiche del cliente . \n",
    "\n",
    "Il dataset analizzato seppur simulativo presentava richieste di prestiti concesse praticamente per metà a persone in affitto, visto l'alto potere predittivo di questa variabile forse sarebbe conveniente diminuire questa percentuale per concentrarsi su profili con una stabilità maggiore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
